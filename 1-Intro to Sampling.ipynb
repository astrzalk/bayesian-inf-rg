{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Gibbs Sampling + MCMC Techniques\n",
    "\n",
    "## Motivation\n",
    "So it might not be that hard to imagine that sampling from any arbitrary distribution might be difficult, but what's the point? There are many answers to that question, but with respect to bayesian inference it all boils down to solving the following equation (which technicially depends on one more equation): \n",
    "$$ E[f(z)] = \\int f(z) p(z)dz = \\int P(y | \\pi) P(\\pi | \\mathcal{X}) d\\pi  = E[P(y | \\pi)] = P(y|\\mathcal{X}). $$\n",
    "The above equation of course depends on the following equation yielded by bayes theorem:\n",
    "$$ P(\\pi | \\mathcal{X}) = \\frac{P(\\mathcal{X} | \\pi ) P(\\pi)}{P(\\mathcal{X})}, $$\n",
    "where $P(\\mathcal{X}) = \\int P(\\mathcal{X}|\\pi) P(\\pi)d\\pi$. Ew integrals! I thought this was statistics not physics. The two integrals are usually intractable when the problem is real enough. Hence, we need to utilize approximations that would ideally in the limit give us the true answer.  \n",
    "\n",
    "The good news is that by the law of large numbers (and probably the ergodic theorem) we have the following equation \n",
    "$$E[f(z)] = \\lim_{N \\to \\infty}\\frac{1}{N} \\sum_{i = 1}^{N} f(z_i)$$\n",
    "where each $z_i$ is sampled from $p(z)$. So basically if we could sample from $p(z)$ we could have our cake and eat it as well!\n",
    "\n",
    "## List of Sampling Methods with Links\n",
    "* [Inverse/Uniform Sampling](https://am207.github.io/2017/wiki/inversetransform.html)\n",
    "* [Rejection Sampling](https://am207.github.io/2017/wiki/rejectionsampling.html)\n",
    "* [Importance Sampling](https://am207.github.io/2017/wiki/importancesampling.html)\n",
    "* MCMC Sampling: Gibbs, Metropolis-Hastings and Hamiltonian Monte Carlo \n",
    "    * [Gibbs Sampling](https://wiseodd.github.io/techblog/2015/10/09/gibbs-sampling/)\n",
    "    * [Metroplis-Hastings](https://wiseodd.github.io/techblog/2015/10/17/metropolis-hastings/)\n",
    "\n",
    "## When to Use Each one\n",
    "If the problem is simple enough the first two sampling algorithms should really suffice as they are really really easy to implement and are relatively efficient. \n",
    "Note when I say problem is simple enough I mean: \n",
    "    1. A low dimensional setting where we can either\n",
    "    2. calculate the CDF of the distribution we are interested in or\n",
    "    3. we can find the right proposal distribution\n",
    "\n",
    "If you can calculate the conditional distribution of the observed variables then use gibbs sampling, if not \n",
    "use Metropolis-Hastings. According to [these lecture notes](https://ermongroup.github.io/cs323-notes/probabilistic/gibbs/) \"in graphical models, the conditional distribution of some variable only depends on the variables in the Markov blanket of that node\". Thus, gibbs sampling tends to be used in these situations a lot.\n",
    "\n",
    "## How to Diagnose Convergence\n",
    "* Autocorrelation \n",
    "* Thinning\n",
    "\n",
    "## Bonus: Cool Visualizations!\n",
    "* [M-H and HMC](http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
